"""Tests for proposeâ†’debate data flow.

Regression tests for #268: proposals generated by step_propose() were lost
between the propose and debate Conductor actions because they were only stored
in-memory and the debate phase only queried GitHub for issues with the
``self-improve:proposed`` label.

The fix passes a mutable ``pending_proposals`` list through _dispatch_action so
that the propose phase can populate it and the debate phase can consume it.
"""

from __future__ import annotations

import json
import subprocess
import sys
from pathlib import Path
from typing import Any
from unittest.mock import AsyncMock, patch

import pytest

_SCRIPTS_DIR = Path(__file__).resolve().parent.parent / "scripts"
sys.path.insert(0, str(_SCRIPTS_DIR))

from main_loop import (  # noqa: E402
    ConductorAction,
    CycleTelemetry,
    _dispatch_action,
)


def _make_telemetry() -> CycleTelemetry:
    return CycleTelemetry(cycle=1)


def _gh_result(stdout: str = "", returncode: int = 0) -> subprocess.CompletedProcess[str]:
    return subprocess.CompletedProcess(args=[], returncode=returncode, stdout=stdout, stderr="")


# ---------------------------------------------------------------------------
# propose phase stores proposals in pending_proposals
# ---------------------------------------------------------------------------


class TestProposeStoresPendingProposals:
    @pytest.mark.anyio
    async def test_propose_populates_pending_proposals(self) -> None:
        """step_propose() results should be stored in pending_proposals."""
        proposals = [
            {"title": "Add linting CI", "description": "Set up ruff in CI", "domain": "dev"},
            {"title": "Expand news sources", "description": "Add Vijesti.me", "domain": "government"},
        ]
        pending: list[dict[str, Any]] = []
        action = ConductorAction(action="propose", reason="time to propose")

        with (
            patch("main_loop.list_backlog_issues", return_value=[]),
            patch("main_loop.step_propose", new_callable=AsyncMock, return_value=proposals),
            patch("main_loop.list_human_suggestions", return_value=[]),
        ):
            await _dispatch_action(
                action,
                telemetry=_make_telemetry(),
                model="test",
                max_pr_rounds=1,
                dry_run=False,
                productive_cycles=0,
                pending_proposals=pending,
            )

        assert len(pending) == 2
        assert pending[0]["title"] == "Add linting CI"
        assert pending[1]["title"] == "Expand news sources"

    @pytest.mark.anyio
    async def test_propose_skipped_when_backlog_nonempty(self) -> None:
        """When backlog has non-analysis issues, propose is skipped and
        pending_proposals stays empty."""
        pending: list[dict[str, Any]] = []
        action = ConductorAction(action="propose", reason="time to propose")

        non_analysis_issue = {
            "number": 42,
            "title": "Fix bug",
            "labels": [{"name": "self-improve:backlog"}],
        }
        with patch("main_loop.list_backlog_issues", return_value=[non_analysis_issue]):
            await _dispatch_action(
                action,
                telemetry=_make_telemetry(),
                model="test",
                max_pr_rounds=1,
                dry_run=False,
                productive_cycles=0,
                pending_proposals=pending,
            )

        assert len(pending) == 0


# ---------------------------------------------------------------------------
# debate phase consumes pending_proposals
# ---------------------------------------------------------------------------


class TestDebateConsumesPendingProposals:
    @pytest.mark.anyio
    async def test_debate_merges_pending_proposals(self) -> None:
        """Debate should include in-memory proposals from the propose phase."""
        pending: list[dict[str, Any]] = [
            {"title": "Add linting CI", "description": "Set up ruff in CI", "domain": "dev"},
        ]
        action = ConductorAction(action="debate", reason="time to debate")

        captured_proposals: list[dict[str, Any]] = []

        async def fake_step_debate(
            proposals: list[dict[str, Any]], *, model: str
        ) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:
            captured_proposals.extend(proposals)
            return proposals, []

        # No GitHub issues with proposed label
        with (
            patch("main_loop._run_gh", return_value=_gh_result("[]")),
            patch("main_loop.step_debate", side_effect=fake_step_debate),
        ):
            await _dispatch_action(
                action,
                telemetry=_make_telemetry(),
                model="test",
                max_pr_rounds=1,
                dry_run=False,
                productive_cycles=0,
                pending_proposals=pending,
            )

        # The in-memory proposal should have been passed to step_debate
        assert len(captured_proposals) == 1
        assert captured_proposals[0]["title"] == "Add linting CI"
        assert captured_proposals[0]["issue_number"] is None
        # pending_proposals should be cleared after debate consumes them
        assert len(pending) == 0

    @pytest.mark.anyio
    async def test_debate_merges_github_and_pending(self) -> None:
        """Debate should merge both GitHub proposals and in-memory proposals."""
        pending: list[dict[str, Any]] = [
            {"title": "In-memory proposal", "description": "From propose phase", "domain": "dev"},
        ]
        action = ConductorAction(action="debate", reason="time to debate")

        gh_issues = [
            {
                "number": 99, "title": "GH proposal", "body": "From GitHub",
                "labels": [{"name": "self-improve:proposed"}],
            },
        ]

        captured_proposals: list[dict[str, Any]] = []

        async def fake_step_debate(
            proposals: list[dict[str, Any]], *, model: str
        ) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:
            captured_proposals.extend(proposals)
            return proposals, []

        with (
            patch("main_loop._run_gh", return_value=_gh_result(json.dumps(gh_issues))),
            patch("main_loop._issue_has_debate_comment", return_value=False),
            patch("main_loop.step_debate", side_effect=fake_step_debate),
        ):
            await _dispatch_action(
                action,
                telemetry=_make_telemetry(),
                model="test",
                max_pr_rounds=1,
                dry_run=False,
                productive_cycles=0,
                pending_proposals=pending,
            )

        # Both GitHub and in-memory proposals should be debated
        assert len(captured_proposals) == 2
        titles = {p["title"] for p in captured_proposals}
        assert "GH proposal" in titles
        assert "In-memory proposal" in titles
        # GitHub proposal has issue_number, in-memory does not
        gh_prop = next(p for p in captured_proposals if p["title"] == "GH proposal")
        mem_prop = next(p for p in captured_proposals if p["title"] == "In-memory proposal")
        assert gh_prop["issue_number"] == 99
        assert mem_prop["issue_number"] is None

    @pytest.mark.anyio
    async def test_debate_with_no_proposals(self) -> None:
        """Debate with no GitHub issues and no pending proposals results in 'no proposals to debate'."""
        pending: list[dict[str, Any]] = []
        action = ConductorAction(action="debate", reason="time to debate")
        telemetry = _make_telemetry()

        with patch("main_loop._run_gh", return_value=_gh_result("[]")):
            await _dispatch_action(
                action,
                telemetry=telemetry,
                model="test",
                max_pr_rounds=1,
                dry_run=False,
                productive_cycles=0,
                pending_proposals=pending,
            )

        # Telemetry should reflect no debates
        assert telemetry.proposals_accepted == 0
        assert telemetry.proposals_rejected == 0

    @pytest.mark.anyio
    async def test_pending_proposals_cleared_after_debate(self) -> None:
        """pending_proposals must be cleared after debate consumes them,
        so re-running debate doesn't re-process the same proposals."""
        pending: list[dict[str, Any]] = [
            {"title": "Proposal A", "description": "Desc A", "domain": "dev"},
            {"title": "Proposal B", "description": "Desc B", "domain": "government"},
        ]
        action = ConductorAction(action="debate", reason="time to debate")

        async def fake_step_debate(
            proposals: list[dict[str, Any]], *, model: str
        ) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:
            return proposals, []

        with (
            patch("main_loop._run_gh", return_value=_gh_result("[]")),
            patch("main_loop.step_debate", side_effect=fake_step_debate),
        ):
            await _dispatch_action(
                action,
                telemetry=_make_telemetry(),
                model="test",
                max_pr_rounds=1,
                dry_run=False,
                productive_cycles=0,
                pending_proposals=pending,
            )

        assert pending == []
